Confidentiality of NLP models
Alignment of NLP models
Examples of work 
- ALIGNING AI WITH SHARED HUMAN VALUES (https://arxiv.org/pdf/2008.02275.pdf)
- Evaluating Large Language Models Trained on Code (https://arxiv.org/pdf/2107.03374.pdf)
- truthfulQA (https://github.com/sylinrl/TruthfulQA)
- AllenNLP Interpret (https://arxiv.org/abs/1909.09251)

adversarial attack (mt, adversaraial, black; another gitproject)

- small
- large-scale 

- backdoor attack 

Integrity of NLP models
- membership inference attack
- model stealing attack 

Study on large-scale NLP models

